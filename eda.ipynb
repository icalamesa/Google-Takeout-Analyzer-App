{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import itertools\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAKEOUT_PATH = \"/home/ivan/Desktop/datasets/Takeout\" # CHANGE IF NECESSARY\n",
    "ACTIVITY_LOG_PATH = os.path.join(TAKEOUT_PATH, \"Mi actividad\")\n",
    "\n",
    "ACTIVITY_PLACEHOLDER_NAME = \"MiActividad.html\"\n",
    "\n",
    "#drive\n",
    "FOLDER_DRIVE_ACTIVITY_LOG_PATH = os.path.join(ACTIVITY_LOG_PATH, \"Drive\")\n",
    "FILE_DRIVE_ACTIVITY_LOG_PATH = os.path.join(FOLDER_DRIVE_ACTIVITY_LOG_PATH, ACTIVITY_PLACEHOLDER_NAME)\n",
    "\n",
    "#takeout\n",
    "FOLDER_DRIVE_ACTIVITY_LOG_PATH = os.path.join(ACTIVITY_LOG_PATH, \"Takeout\")\n",
    "FILE_TAKEOUT_ACTIVITY_LOG_PATH = os.path.join(FOLDER_DRIVE_ACTIVITY_LOG_PATH, ACTIVITY_PLACEHOLDER_NAME)\n",
    "\n",
    "#youtube\n",
    "FOLDER_DRIVE_ACTIVITY_LOG_PATH = os.path.join(ACTIVITY_LOG_PATH, \"YouTube\")\n",
    "FILE_YOUTUBE_ACTIVITY_LOG_PATH = os.path.join(FOLDER_DRIVE_ACTIVITY_LOG_PATH, ACTIVITY_PLACEHOLDER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_contents(file_path, chunk_size=524288):\n",
    "    \"\"\"\n",
    "    Generator function that reads an HTML file in chunks to avoid loading the entire file into memory.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str): Path to the HTML file.\n",
    "    - chunk_size (int): Size of each chunk in bytes. Default is 512 KB.\n",
    "    \n",
    "    Yields:\n",
    "    - str: A chunk of HTML that ends on a complete tag.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        buffer = ''\n",
    "        while True:\n",
    "            data = file.read(chunk_size)\n",
    "            if not data:\n",
    "                # Only yield the remaining buffer if it's a valid chunk with a closed tag\n",
    "                if buffer:\n",
    "                    yield buffer\n",
    "                break\n",
    "\n",
    "            buffer += data\n",
    "            last_tag_end = max(buffer.rfind('>'), buffer.rfind('/>'))\n",
    "            if last_tag_end == -1:\n",
    "                continue  # Continue reading into buffer until a tag end is found\n",
    "\n",
    "            # Yield up to the last complete tag and adjust the buffer\n",
    "            yield buffer[:last_tag_end + 1]\n",
    "            buffer = buffer[last_tag_end + 1:]\n",
    "\n",
    "\n",
    "def process_chunk(html_content):\n",
    "    \"\"\"\n",
    "    Processes a chunk of HTML to extract relevant data from specified div elements, including a timestamp.\n",
    "    \n",
    "    Args:\n",
    "    - html_content (str): A string of HTML content.\n",
    "    \n",
    "    Returns:\n",
    "    - list of dict: Extracted data from each content cell in the HTML chunk.\n",
    "    \"\"\"\n",
    "    strainer = SoupStrainer('div', class_=\"outer-cell mdl-cell mdl-cell--12-col mdl-shadow--2dp\")\n",
    "    soup = BeautifulSoup(html_content, 'html.parser', parse_only=strainer)\n",
    "    entries = []\n",
    "    count = 0\n",
    "    \n",
    "    for outer_div in soup.find_all('div', recursive=False):\n",
    "        content_cells = outer_div.find_all('div', class_=\"content-cell mdl-cell mdl-cell--6-col mdl-typography--body-1\")\n",
    "        for div in content_cells:\n",
    "            links = div.find_all('a', href=True)\n",
    "            stripped_strings = list(div.stripped_strings)\n",
    "            platform = \"platform\"\n",
    "            link_action_text = links[0].get_text(strip=True) if len(links) > 0 else ''\n",
    "            \n",
    "            if stripped_strings:\n",
    "                action_parts = stripped_strings[0].split('|')\n",
    "                action_code = action_parts[0].strip()\n",
    "                timestamp = stripped_strings[-1].strip()\n",
    "            else:\n",
    "                action_code = ''\n",
    "                timestamp = ''\n",
    "\n",
    "            entry = {\n",
    "                \"platform\": platform,\n",
    "                \"action_code\": action_code,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"link_action_name\": links[0]['href'] if len(links) > 0 else '',\n",
    "                \"link_action_text\": link_action_text,\n",
    "                \"channel_link\": links[1]['href'] if len(links) > 1 else '',\n",
    "                \"channel_name\": links[1].get_text(strip=True) if len(links) > 1 else '',\n",
    "                \"link3\": links[2]['href'] if len(links) > 2 else '',\n",
    "                \"link3_text\": links[2].get_text(strip=True) if len(links) > 2 else ''\n",
    "            }\n",
    "            entries.append(entry)\n",
    "    \n",
    "    return entries\n",
    "\n",
    "\n",
    "def read_html(file_path):\n",
    "    \"\"\"\n",
    "    Main function to process an HTML file, extract data, and write to a CSV file using multiprocessing.\n",
    "    Dynamically adjusts the number of processes based on the file size.\n",
    "    \n",
    "    Args:\n",
    "    - file_path (str): Path to the HTML file.\n",
    "    \"\"\"\n",
    "    # TO DO: MAKE THE INDIVIDUAL THREADS STORE THE DATA THEMSELVES TO MAKE THE OPERATIONS ASYNC\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    chunk_size = 524288  # 512 KB\n",
    "    num_chunks = (file_size // chunk_size) + 1 \n",
    "    \n",
    "    if num_chunks < 4:\n",
    "        num_processes = num_chunks\n",
    "    else:\n",
    "        num_processes = 4\n",
    "    \n",
    "    chunks = get_html_contents(file_path, chunk_size=chunk_size)\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        result_iter = pool.imap(process_chunk, chunks)\n",
    "        results = list(itertools.chain.from_iterable(result_iter))\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv('output.csv', index=False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>action_code</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>link_action_name</th>\n",
       "      <th>link_action_text</th>\n",
       "      <th>channel_link</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>link3</th>\n",
       "      <th>link3_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>platform</td>\n",
       "      <td>Se ha iniciado una descarga en bloque en Drive</td>\n",
       "      <td>10 sept 2023, 18:29:17 CET</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>platform</td>\n",
       "      <td>Se ha iniciado una descarga en bloque en Drive</td>\n",
       "      <td>3 dic 2021, 19:36:31 CET</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   platform                                     action_code  \\\n",
       "0  platform  Se ha iniciado una descarga en bloque en Drive   \n",
       "1  platform  Se ha iniciado una descarga en bloque en Drive   \n",
       "\n",
       "                    timestamp link_action_name link_action_text channel_link  \\\n",
       "0  10 sept 2023, 18:29:17 CET                                                  \n",
       "1    3 dic 2021, 19:36:31 CET                                                  \n",
       "\n",
       "  channel_name link3 link3_text  \n",
       "0                                \n",
       "1                                "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_html(FILE_DRIVE_ACTIVITY_LOG_PATH)\n",
    "#print(len(df))\n",
    "#value_counts = df[\"action_code\"].value_counts().sort_values(ascending=False)    \n",
    "#value_counts.head(50)\n",
    "\n",
    "df[df['action_code'].str.len() > 15].head(30)\n",
    "#value_counts = df[\"complete_action\"].value_counts().sort_values(ascending=False)  \n",
    "#value_counts.head(50) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
